{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de96ee9d",
   "metadata": {},
   "source": [
    "# PokeGan: A Generative Adversarial Networks Example.\n",
    "\n",
    "\n",
    "In this notebook we are going to design and implement a simple Generative Adversarial Network (GAN) to generate a musical melody. I have always loved the themes of Pokemon and so we will use a dataset comprised of transcriptions from the Pokemon games."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e97184",
   "metadata": {},
   "source": [
    "### GANS: an overview.\n",
    "\n",
    "The GAN architecture is relatively simple and detailed in a paper by Goodfellow et. al. (2014) [1]. It is comprised of two networks: a discriminator (D) and generator (G). These networks then participate in a two player game whereby the generator generates a plausible data point from a random vector in its latent space. The discriminator takes a generated sample and a real sample and decides to classify these as real and fake. This classification informs the loss for both G and D.\n",
    "\n",
    "The game finishes when the discriminator cannot decide between the real and fake samples. This happens when the classification probability is no better than 50% and when D cannot be improved via backpropogation. Convergence is, in general, non-trivial when dealing the GANs. Before we detail the network implementation details we will first import our package dependencies and datasets. The data will largely determine the structure of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da18233c",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d9b9ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mido'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmido\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mido'"
     ]
    }
   ],
   "source": [
    "import torch as tch # PyTorch is a very user friendly high level deep learning package framework. See also: TensorFlow and Keras.\n",
    "from torch import nn # this is a class container for neural newtworks will be extended.\n",
    "\n",
    "import math as math\n",
    "import os\n",
    "import mido as md\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b720f9",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "As always, data is the most important component of the machine learning pipeline. The primary goal is to generate a sequence of sounds which resemble a track from the Pokemon universe when played through a set of speakers. The first layer of processing we are going to do is cognitive: we don't want to concern ourselves with all the physics of sound production as that would make out output space large and therefore difficult to work with. \n",
    "\n",
    "The first key insight we can make hear is that most music sounds recognisable when the right notes are played in the right order through some generic implementation of an instrument: this sounds facetious but it greatly simplfies the problem. This has been thought about before and the MIDI data standard was created. This data splits a song, roughly, into a series of tracks with regular intervals. In every interval of every track there is a symbolic representation of the note (in the 12-note Western interpretation of music: the standard is not perfect but is sufficient for this project).\n",
    "\n",
    "This data structure works well for a neural network: we aim to predict a temporal sequence of tracks and notes. The simplest version of this structure would be a single track with a single note i.e. a melody. The temporal sequence immediately suggests some neural network architectures.\n",
    "\n",
    "I have a collection of MIDI transcriptions of the Pokemon game files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block containing imported data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50270505",
   "metadata": {},
   "source": [
    "It is usually necessary to do some data cleaning. The neural network structure is flexible enough to handle variable time lengths as a generator however to keep things consistent we will choose a fixed time length of 30s. Therefore all our data is clipped into 30 second windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f1abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block containing the data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad0202a",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "This is the fun bit - we get to choose how to interact with the data through our choice of models for discriminator and generator. \n",
    "\n",
    "The generator network has, to my eyes, a potential structure suggested by the data: a recurrent neural network called the long-short term memory network (LSTM). The LSTM network is essentially a reccurent neural network that is gated to allow for selective forgetfulness/remembering at variable time-scales and was designed to overcome some of the issues with traditional RNNs; more can be read here [2]. The LSTM is certainly not the only choice we could have made: Transformers, CNN's, MLP's are all perfectly fine candidates.\n",
    "\n",
    "The discriminator network is just a classifier. It would be best to have the final layer as a Dense (fully connected) layer to the outputs [O1, O2]. The rest of the network should probably exploit the time-sequence structure of the data and so an LSTM is again a good candidate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c3e0b",
   "metadata": {},
   "source": [
    "#### Generator\n",
    "\n",
    "The generator needs to take a random input sequence and then output a MIDI file. We are going to keep it simple and just use one random number for each 1/32nd note length. We have 30 seconds of music at a tempo of 125 bpm giving us a sequence length of L = 0.5*30*125*4*8 = 60000. The number of input features is 1. There are 88 notes on the piano roll and we will use 5 channels corresponding to five sounds and therefore our output is (L, 88, 5).\n",
    "\n",
    "We can juice the model up with a number of LSTM layers feeding into each other. This is a fairly simple project so we wont do that keeping the number of layers at 1. Within each layer we can specify the number of hidden states which correspond to what is passed to the next input (or next LSTM cell) as a result of the internal gating. For variety we will select 2 hidden features to be passed forward.\n",
    "\n",
    "We need to regularise the network to prevent overfitting and the most common way to do this is to use dropout. For this model we will use a dropout of 0.4. We will assume that the LSTM is not bidirectional and we will present the data ubnatched for simplicity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611e0863",
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super.()__init__() # our class inherits the super class nn.Module and we initialise that here\n",
    "        # model structure\n",
    "        l1 = nn.LSTM(1, 88*5, 1)\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
